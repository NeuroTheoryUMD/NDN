

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>FFnetwork package &mdash; Neural Deep Network 2.0 documentation</title>
  

  
  
  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  

  

  
        <link rel="index" title="Index"
              href="../genindex.html"/>
        <link rel="search" title="Search" href="../search.html"/>
    <link rel="top" title="Neural Deep Network 2.0 documentation" href="../index.html"/> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> Neural Deep Network
          

          
          </a>

          
            
            
              <div class="version">
                2.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <!-- Local TOC -->
              <div class="local-toc"><ul>
<li><a class="reference internal" href="#">FFnetwork package</a><ul>
<li><a class="reference internal" href="#submodules">Submodules</a></li>
<li><a class="reference internal" href="#module-FFnetwork.create_reg_matrices">FFnetwork.create_reg_matrices module</a></li>
<li><a class="reference internal" href="#module-FFnetwork.ffnetwork">FFnetwork.ffnetwork module</a></li>
<li><a class="reference internal" href="#module-FFnetwork.layer">FFnetwork.layer module</a></li>
<li><a class="reference internal" href="#module-FFnetwork.regularization">FFnetwork.regularization module</a></li>
<li><a class="reference internal" href="#ffnetwork-side-network-module">FFnetwork.side_network module</a></li>
<li><a class="reference internal" href="#module-FFnetwork">Module contents</a></li>
</ul>
</li>
</ul>
</div>
            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Neural Deep Network</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
      <li>FFnetwork package</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/source/FFnetwork.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="ffnetwork-package">
<h1>FFnetwork package<a class="headerlink" href="#ffnetwork-package" title="Permalink to this headline">¶</a></h1>
<div class="section" id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="module-FFnetwork.create_reg_matrices">
<span id="ffnetwork-create-reg-matrices-module"></span><h2>FFnetwork.create_reg_matrices module<a class="headerlink" href="#module-FFnetwork.create_reg_matrices" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="FFnetwork.create_reg_matrices.create_Tikhonov_matrix">
<code class="descclassname">FFnetwork.create_reg_matrices.</code><code class="descname">create_Tikhonov_matrix</code><span class="sig-paren">(</span><em>stim_dims</em>, <em>reg_type</em>, <em>boundary_conditions=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/FFnetwork/create_reg_matrices.html#create_Tikhonov_matrix"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#FFnetwork.create_reg_matrices.create_Tikhonov_matrix" title="Permalink to this definition">¶</a></dt>
<dd><p>Tmat = create_Tikhonov_matrix(stim_params, direction, order)</p>
<p>Creates a matrix specifying a an L2-regularization operator of the form
||T*k||^2. Currently only supports second derivative/Laplacian operations</p>
<dl class="docutils">
<dt>INPUTS:</dt>
<dd><dl class="first docutils">
<dt>stim_params: parameter struct associated with the target stimulus.</dt>
<dd>must contain .dims field specifying the number of stimulus elements along each dimension
&lt;.boundary_conds&gt; specifies boundary conditions: Inf is free boundary, 0 is tied to 0, and -1 is periodic
&lt;.split_pts&gt; specifies an ‘internal boundary’ over which we dont want to smooth. [direction split_ind split_bnd]</dd>
</dl>
<p class="last">direction: direction of the derivative relative to the stimulus dimensions. e.g. 1 is along the first dim, 2 is along the second, [1 2] is a laplacian</p>
</dd>
<dt>OUTPUTS:</dt>
<dd>Tmat: sparse matrix specifying the desired Tikhonov operation</dd>
</dl>
<p># Boundary conditions would be ideally a dictionary with each reg type listed. Assumed infinity without
#   Currently not implemented</p>
<p>The method of computing sparse differencing matrices used here is adapted from
Bryan C. Smith’s and Andrew V. Knyazev’s function “laplacian”, available
here: <a class="reference external" href="http://www.mathworks.com/matlabcentral/fileexchange/27279-laplacian-in-1d-2d-or-3d">http://www.mathworks.com/matlabcentral/fileexchange/27279-laplacian-in-1d-2d-or-3d</a>
Written in Matlab by James McFarland, adapted into python by Dan Butts</p>
</dd></dl>

<dl class="function">
<dt id="FFnetwork.create_reg_matrices.create_maxpenalty_matrix">
<code class="descclassname">FFnetwork.create_reg_matrices.</code><code class="descname">create_maxpenalty_matrix</code><span class="sig-paren">(</span><em>input_dims</em>, <em>reg_type</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/FFnetwork/create_reg_matrices.html#create_maxpenalty_matrix"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#FFnetwork.create_reg_matrices.create_maxpenalty_matrix" title="Permalink to this definition">¶</a></dt>
<dd><p>Tmat = create_Tikhonov_matrix(stim_params, direction, order)</p>
<p>Creates a matrix specifying a an L2-regularization operator of the form
||T*k||^2. Currently only supports second derivative/Laplacian operations</p>
<dl class="docutils">
<dt>INPUTS:</dt>
<dd><dl class="first docutils">
<dt>stim_params: parameter struct associated with the target stimulus.</dt>
<dd>must contain .dims field specifying the number of stimulus elements along each dimension
&lt;.boundary_conds&gt; specifies boundary conditions: Inf is free boundary, 0 is tied to 0, and -1 is periodic
&lt;.split_pts&gt; specifies an ‘internal boundary’ over which we dont want to smooth. [direction split_ind split_bnd]</dd>
</dl>
<p class="last">direction: direction of the derivative relative to the stimulus dimensions. e.g. 1 is along the first dim, 2 is along the second, [1 2] is a laplacian</p>
</dd>
<dt>OUTPUTS:</dt>
<dd>Tmat: sparse matrix specifying the desired Tikhonov operation</dd>
</dl>
<p># Boundary conditions would be ideally a dictionary with each reg type listed. Assumed infinity without
#   Currently not implemented</p>
<p>The method of computing sparse differencing matrices used here is adapted from
Bryan C. Smith’s and Andrew V. Knyazev’s function “laplacian”, available
here: <a class="reference external" href="http://www.mathworks.com/matlabcentral/fileexchange/27279-laplacian-in-1d-2d-or-3d">http://www.mathworks.com/matlabcentral/fileexchange/27279-laplacian-in-1d-2d-or-3d</a>
Written in Matlab by James McFarland, adapted into python by Dan Butts</p>
</dd></dl>

</div>
<div class="section" id="module-FFnetwork.ffnetwork">
<span id="ffnetwork-ffnetwork-module"></span><h2>FFnetwork.ffnetwork module<a class="headerlink" href="#module-FFnetwork.ffnetwork" title="Permalink to this headline">¶</a></h2>
<p>Basic network-building tools</p>
<dl class="class">
<dt id="FFnetwork.ffnetwork.FFNetwork">
<em class="property">class </em><code class="descclassname">FFnetwork.ffnetwork.</code><code class="descname">FFNetwork</code><span class="sig-paren">(</span><em>scope=None</em>, <em>input_dims=None</em>, <em>params_dict=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/FFnetwork/ffnetwork.html#FFNetwork"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#FFnetwork.ffnetwork.FFNetwork" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">object</span></code></p>
<p>Implementation of simple fully connected feedforward neural network</p>
<dl class="attribute">
<dt id="FFnetwork.ffnetwork.FFNetwork.scope">
<code class="descname">scope</code><a class="headerlink" href="#FFnetwork.ffnetwork.FFNetwork.scope" title="Permalink to this definition">¶</a></dt>
<dd><p><em>str</em> – name scope for network</p>
</dd></dl>

<dl class="attribute">
<dt id="FFnetwork.ffnetwork.FFNetwork.layers">
<code class="descname">layers</code><a class="headerlink" href="#FFnetwork.ffnetwork.FFNetwork.layers" title="Permalink to this definition">¶</a></dt>
<dd><p>list of <cite>Layer</cite> objects – layers of network</p>
</dd></dl>

<dl class="attribute">
<dt id="FFnetwork.ffnetwork.FFNetwork.num_layers">
<code class="descname">num_layers</code><a class="headerlink" href="#FFnetwork.ffnetwork.FFNetwork.num_layers" title="Permalink to this definition">¶</a></dt>
<dd><p><em>int</em> – number of layers in network (not including input)</p>
</dd></dl>

<dl class="attribute">
<dt id="FFnetwork.ffnetwork.FFNetwork.log">
<code class="descname">log</code><a class="headerlink" href="#FFnetwork.ffnetwork.FFNetwork.log" title="Permalink to this definition">¶</a></dt>
<dd><p><em>bool</em> – use tf summary writers in layer activations</p>
</dd></dl>

<dl class="method">
<dt id="FFnetwork.ffnetwork.FFNetwork.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>scope=None</em>, <em>input_dims=None</em>, <em>params_dict=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/FFnetwork/ffnetwork.html#FFNetwork.__init__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#FFnetwork.ffnetwork.FFNetwork.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Constructor for FFNetwork class</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>scope</strong> (<em>str</em>) – name scope for network</li>
<li><strong>params_dict</strong> (<em>dict</em>) – contains parameters about details of FFnetwork:</li>
<li><strong>layer_sizes</strong> (<em>-&gt;</em>) – list of layer sizes, including input
and output. All arguments (input size) can be up to a
3-dimensional list. REQUIRED (NO DEFAULT)</li>
<li><strong>num_inh</strong> (<em>-&gt;</em>) – list or single number denoting number of inhibitory units in each
layer. This specifies the output of that number of units multiplied by -1
DEFAULT = 0 (and having any single value will be used for all layers)</li>
<li><strong>activation_funcs</strong> (<em>-&gt;</em>) – pointwise
function for each layer; replicated if a single element.
DEFAULT = ‘relu’. See Layer class for other options.</li>
<li><strong>pos_constraints</strong> (<em>-&gt;</em>) – constrains all weights to be positive
DEFAULTS = False.</li>
<li><strong>reg_initializer</strong> (<em>-&gt;</em>) – a list of dictionaries: one for each layer. Within the
dictionary, reg_type/vals as key-value pairs.
DEFAULT = None</li>
<li><strong>weights_initializer</strong> (<em>-&gt;</em>) – initializer
for the weights in each layer; replicated if a single element.
DEFAULT = ‘trunc_normal’. See Layer class for other options.</li>
<li><strong>biases_initializer</strong> (<em>-&gt;</em>) – initializer for
the biases in each layer; replicated if a single element.
DEFAULT = ‘zeros’. See Layer class for other options.</li>
<li><strong>log_activations</strong> (<em>-&gt;</em>) – True to use tf.summary on layer activations
DEFAULT = False</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Raises:</th><td class="field-body"><ul class="first last simple">
<li><code class="xref py py-exc docutils literal"><span class="pre">TypeError</span></code> – If <cite>scope</cite> is not specified</li>
<li><code class="xref py py-exc docutils literal"><span class="pre">TypeError</span></code> – If <cite>inputs</cite> is not specified</li>
<li><code class="xref py py-exc docutils literal"><span class="pre">TypeError</span></code> – If <cite>layer_sizes</cite> is not specified</li>
<li><code class="xref py py-exc docutils literal"><span class="pre">ValueError</span></code> – If <cite>activation_funcs</cite> is not a properly-sized list</li>
<li><code class="xref py py-exc docutils literal"><span class="pre">ValueError</span></code> – If <cite>weights_initializer</cite> is not a properly-sized list</li>
<li><code class="xref py py-exc docutils literal"><span class="pre">ValueError</span></code> – If <cite>biases_initializer</cite> is not a properly-sized list</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="FFnetwork.ffnetwork.FFNetwork.assign_model_params">
<code class="descname">assign_model_params</code><span class="sig-paren">(</span><em>sess</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/FFnetwork/ffnetwork.html#FFNetwork.assign_model_params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#FFnetwork.ffnetwork.FFNetwork.assign_model_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Read weights/biases in numpy arrays into tf Variables</p>
</dd></dl>

<dl class="method">
<dt id="FFnetwork.ffnetwork.FFNetwork.assign_reg_vals">
<code class="descname">assign_reg_vals</code><span class="sig-paren">(</span><em>sess</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/FFnetwork/ffnetwork.html#FFNetwork.assign_reg_vals"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#FFnetwork.ffnetwork.FFNetwork.assign_reg_vals" title="Permalink to this definition">¶</a></dt>
<dd><p>Update default tf Graph with new regularization penalties</p>
</dd></dl>

<dl class="method">
<dt id="FFnetwork.ffnetwork.FFNetwork.build_graph">
<code class="descname">build_graph</code><span class="sig-paren">(</span><em>inputs</em>, <em>params_dict=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/FFnetwork/ffnetwork.html#FFNetwork.build_graph"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#FFnetwork.ffnetwork.FFNetwork.build_graph" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="FFnetwork.ffnetwork.FFNetwork.define_regularization_loss">
<code class="descname">define_regularization_loss</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/FFnetwork/ffnetwork.html#FFNetwork.define_regularization_loss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#FFnetwork.ffnetwork.FFNetwork.define_regularization_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Build regularization loss portion of default tf graph</p>
</dd></dl>

<dl class="method">
<dt id="FFnetwork.ffnetwork.FFNetwork.write_model_params">
<code class="descname">write_model_params</code><span class="sig-paren">(</span><em>sess</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/FFnetwork/ffnetwork.html#FFNetwork.write_model_params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#FFnetwork.ffnetwork.FFNetwork.write_model_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Write weights/biases in tf Variables to numpy arrays</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="FFnetwork.ffnetwork.side_network">
<em class="property">class </em><code class="descclassname">FFnetwork.ffnetwork.</code><code class="descname">side_network</code><span class="sig-paren">(</span><em>scope=None</em>, <em>input_network_params=None</em>, <em>params_dict=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/FFnetwork/ffnetwork.html#side_network"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#FFnetwork.ffnetwork.side_network" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#FFnetwork.ffnetwork.FFNetwork" title="FFnetwork.ffnetwork.FFNetwork"><code class="xref py py-class docutils literal"><span class="pre">FFnetwork.ffnetwork.FFNetwork</span></code></a></p>
<p>Implementation of siFFNetwork</p>
<dl class="method">
<dt id="FFnetwork.ffnetwork.side_network.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>scope=None</em>, <em>input_network_params=None</em>, <em>params_dict=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/FFnetwork/ffnetwork.html#side_network.__init__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#FFnetwork.ffnetwork.side_network.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Constructor for Network class</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>scope</strong> (<em>str</em>) – name scope for network</li>
<li><strong>input_network_params</strong> – parameters of network that is input to this network</li>
<li><strong>params_dict</strong> (<em>dictionary with the following fields</em>) – <p>SI-NETWORK SPECIFIC:
-&gt; first_filter_size: size of filters in first layer, if different than input size</p>
<blockquote>
<div>DEFAULT = input size</div></blockquote>
<dl class="docutils">
<dt>-&gt; shift_spacing (int): convolutional “strides” to be passed back into conv2d</dt>
<dd>DEFAULT = 1</dd>
<dt>-&gt; binocular (boolean): currently doesn’t work</dt>
<dd>DEFAULT = FALSE</dd>
</dl>
<p>INHERITED FFNetwork PARAMS (see FFNetwork documentation):
-&gt; layer_sizes (list of ints)
-&gt; activation_funcs (str or list of strs, optional)
-&gt; weights_initializer (str or list of strs, optional)
-&gt; biases_initializer (str or list of strs, optional)
-&gt; reg_initializers (list of dicts)
-&gt; num_inh (None, int or list of ints, optional)
-&gt; pos_constraint (bool or list of bools, optional):
-&gt; log_activations (bool, optional)</p>
</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Raises:</th><td class="field-body"><ul class="first last simple">
<li><code class="xref py py-exc docutils literal"><span class="pre">TypeError</span></code> – If <cite>scope</cite> is not specified</li>
<li><code class="xref py py-exc docutils literal"><span class="pre">TypeError</span></code> – If <cite>inputs</cite> is not specified</li>
<li><code class="xref py py-exc docutils literal"><span class="pre">TypeError</span></code> – If <cite>layer_sizes</cite> is not specified</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="FFnetwork.ffnetwork.side_network.build_graph">
<code class="descname">build_graph</code><span class="sig-paren">(</span><em>input_network</em>, <em>params_dict=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/FFnetwork/ffnetwork.html#side_network.build_graph"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#FFnetwork.ffnetwork.side_network.build_graph" title="Permalink to this definition">¶</a></dt>
<dd><p>Note this is different from other network build-graphs in that the whole
network graph, rather than just a link to its output, so that it can be assembled here</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-FFnetwork.layer">
<span id="ffnetwork-layer-module"></span><h2>FFnetwork.layer module<a class="headerlink" href="#module-FFnetwork.layer" title="Permalink to this headline">¶</a></h2>
<p>Basic layer definitions</p>
<dl class="class">
<dt id="FFnetwork.layer.Layer">
<em class="property">class </em><code class="descclassname">FFnetwork.layer.</code><code class="descname">Layer</code><span class="sig-paren">(</span><em>scope=None</em>, <em>input_dims=None</em>, <em>filter_dims=None</em>, <em>output_dims=None</em>, <em>activation_func='relu'</em>, <em>normalize_weights=False</em>, <em>weights_initializer='trunc_normal'</em>, <em>biases_initializer='zeros'</em>, <em>reg_initializer=None</em>, <em>num_inh=0</em>, <em>pos_constraint=False</em>, <em>log_activations=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/FFnetwork/layer.html#Layer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#FFnetwork.layer.Layer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">object</span></code></p>
<p>Implementation of fully connected neural network layer</p>
<dl class="attribute">
<dt id="FFnetwork.layer.Layer.scope">
<code class="descname">scope</code><a class="headerlink" href="#FFnetwork.layer.Layer.scope" title="Permalink to this definition">¶</a></dt>
<dd><p><em>str</em> – name scope for variables and operations in layer</p>
</dd></dl>

<dl class="attribute">
<dt id="FFnetwork.layer.Layer.input_dims">
<code class="descname">input_dims</code><a class="headerlink" href="#FFnetwork.layer.Layer.input_dims" title="Permalink to this definition">¶</a></dt>
<dd><p><em>list</em> – inputs to layer</p>
</dd></dl>

<dl class="attribute">
<dt id="FFnetwork.layer.Layer.output_dims">
<code class="descname">output_dims</code><a class="headerlink" href="#FFnetwork.layer.Layer.output_dims" title="Permalink to this definition">¶</a></dt>
<dd><p><em>list</em> – outputs of layer</p>
</dd></dl>

<dl class="attribute">
<dt id="FFnetwork.layer.Layer.outputs">
<code class="descname">outputs</code><a class="headerlink" href="#FFnetwork.layer.Layer.outputs" title="Permalink to this definition">¶</a></dt>
<dd><p><em>tf Tensor</em> – output of layer</p>
</dd></dl>

<dl class="attribute">
<dt id="FFnetwork.layer.Layer.num_inh">
<code class="descname">num_inh</code><a class="headerlink" href="#FFnetwork.layer.Layer.num_inh" title="Permalink to this definition">¶</a></dt>
<dd><p><em>int</em> – number of inhibitory units in layer</p>
</dd></dl>

<dl class="attribute">
<dt id="FFnetwork.layer.Layer.weights_ph">
<code class="descname">weights_ph</code><a class="headerlink" href="#FFnetwork.layer.Layer.weights_ph" title="Permalink to this definition">¶</a></dt>
<dd><p><em>tf placeholder</em> – placeholder for weights in layer</p>
</dd></dl>

<dl class="attribute">
<dt id="FFnetwork.layer.Layer.biases_ph">
<code class="descname">biases_ph</code><a class="headerlink" href="#FFnetwork.layer.Layer.biases_ph" title="Permalink to this definition">¶</a></dt>
<dd><p><em>tf placeholder</em> – placeholder for biases in layer</p>
</dd></dl>

<dl class="attribute">
<dt id="FFnetwork.layer.Layer.weights_var">
<code class="descname">weights_var</code><a class="headerlink" href="#FFnetwork.layer.Layer.weights_var" title="Permalink to this definition">¶</a></dt>
<dd><p><em>tf Tensor</em> – weights in layer</p>
</dd></dl>

<dl class="attribute">
<dt id="FFnetwork.layer.Layer.biases_var">
<code class="descname">biases_var</code><a class="headerlink" href="#FFnetwork.layer.Layer.biases_var" title="Permalink to this definition">¶</a></dt>
<dd><p><em>tf Tensor</em> – biases in layer</p>
</dd></dl>

<dl class="attribute">
<dt id="FFnetwork.layer.Layer.weights">
<code class="descname">weights</code><a class="headerlink" href="#FFnetwork.layer.Layer.weights" title="Permalink to this definition">¶</a></dt>
<dd><p><em>numpy array</em> – shadow variable of <cite>weights_var</cite> that allows for
easier manipulation outside of tf sessions</p>
</dd></dl>

<dl class="attribute">
<dt id="FFnetwork.layer.Layer.biases">
<code class="descname">biases</code><a class="headerlink" href="#FFnetwork.layer.Layer.biases" title="Permalink to this definition">¶</a></dt>
<dd><p><em>numpy array</em> – shadow variable of <cite>biases_var</cite> that allows for
easier manipulation outside of tf sessions</p>
</dd></dl>

<dl class="attribute">
<dt id="FFnetwork.layer.Layer.activation_func">
<code class="descname">activation_func</code><a class="headerlink" href="#FFnetwork.layer.Layer.activation_func" title="Permalink to this definition">¶</a></dt>
<dd><p><em>tf activation function</em> – activation function in layer</p>
</dd></dl>

<dl class="attribute">
<dt id="FFnetwork.layer.Layer.reg">
<code class="descname">reg</code><a class="headerlink" href="#FFnetwork.layer.Layer.reg" title="Permalink to this definition">¶</a></dt>
<dd><p><em>Regularization object</em> – holds regularizations values and matrices
(as tf constants) for layer</p>
</dd></dl>

<dl class="attribute">
<dt id="FFnetwork.layer.Layer.ei_mask_var">
<code class="descname">ei_mask_var</code><a class="headerlink" href="#FFnetwork.layer.Layer.ei_mask_var" title="Permalink to this definition">¶</a></dt>
<dd><p><em>tf constant</em> – mask of +/-1s to multiply output of layer</p>
</dd></dl>

<dl class="attribute">
<dt id="FFnetwork.layer.Layer.ei_mask">
<code class="descname">ei_mask</code><a class="headerlink" href="#FFnetwork.layer.Layer.ei_mask" title="Permalink to this definition">¶</a></dt>
<dd><p><em>list</em> – mask of +/-1s to multiply output of layer; shadows
<cite>ei_mask_tf</cite> for easier manipulation outside of tf sessions</p>
</dd></dl>

<dl class="attribute">
<dt id="FFnetwork.layer.Layer.pos_constraint">
<code class="descname">pos_constraint</code><a class="headerlink" href="#FFnetwork.layer.Layer.pos_constraint" title="Permalink to this definition">¶</a></dt>
<dd><p><em>bool</em> – positivity constraint on weights in layer</p>
</dd></dl>

<dl class="attribute">
<dt id="FFnetwork.layer.Layer.log">
<code class="descname">log</code><a class="headerlink" href="#FFnetwork.layer.Layer.log" title="Permalink to this definition">¶</a></dt>
<dd><p><em>bool</em> – use tf summary writers on layer output</p>
</dd></dl>

<dl class="method">
<dt id="FFnetwork.layer.Layer.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>scope=None</em>, <em>input_dims=None</em>, <em>filter_dims=None</em>, <em>output_dims=None</em>, <em>activation_func='relu'</em>, <em>normalize_weights=False</em>, <em>weights_initializer='trunc_normal'</em>, <em>biases_initializer='zeros'</em>, <em>reg_initializer=None</em>, <em>num_inh=0</em>, <em>pos_constraint=False</em>, <em>log_activations=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/FFnetwork/layer.html#Layer.__init__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#FFnetwork.layer.Layer.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Constructor for Layer class</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>scope</strong> (<em>str</em>) – name scope for variables and operations in layer</li>
<li><strong>input_dims</strong> (<em>int</em><em> or </em><em>list</em>) – dimensions of input data</li>
<li><strong>output_dims</strong> (<em>int</em><em> or </em><em>list</em>) – dimensions of output data</li>
<li><strong>activation_func</strong> (<em>str</em><em>, </em><em>optional</em>) – pointwise function applied to
output of affine transformation
[‘relu’] | ‘sigmoid’ | ‘tanh’ | ‘identity’ | ‘softplus’ |
‘elu’ | ‘quad’</li>
<li><strong>weights_initializer</strong> (<em>str</em><em>, </em><em>optional</em>) – initializer for the weights
[‘trunc_normal’] | ‘normal’ | ‘zeros’</li>
<li><strong>biases_initializer</strong> (<em>str</em><em>, </em><em>optional</em>) – initializer for the biases
‘trunc_normal’ | ‘normal’ | [‘zeros’]</li>
<li><strong>reg_initializer</strong> (<em>dict</em><em>, </em><em>optional</em>) – see Regularizer docs for info</li>
<li><strong>num_inh</strong> (<em>int</em><em>, </em><em>optional</em>) – number of inhibitory units in layer</li>
<li><strong>pos_constraint</strong> (<em>bool</em><em>, </em><em>optional</em>) – True to constrain layer weights to
be positive</li>
<li><strong>log_activations</strong> (<em>bool</em><em>, </em><em>optional</em>) – True to use tf.summary on layer
activations</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Raises:</th><td class="field-body"><ul class="first last simple">
<li><code class="xref py py-exc docutils literal"><span class="pre">TypeError</span></code> – If <cite>variable_scope</cite> is not specified</li>
<li><code class="xref py py-exc docutils literal"><span class="pre">TypeError</span></code> – If <cite>inputs</cite> is not specified</li>
<li><code class="xref py py-exc docutils literal"><span class="pre">TypeError</span></code> – If <cite>num_inputs</cite> or <cite>num_outputs</cite> is not specified</li>
<li><code class="xref py py-exc docutils literal"><span class="pre">ValueError</span></code> – If <cite>num_inh</cite> is greater than total number of units</li>
<li><code class="xref py py-exc docutils literal"><span class="pre">ValueError</span></code> – If <cite>activation_func</cite> is not a valid string</li>
<li><code class="xref py py-exc docutils literal"><span class="pre">ValueError</span></code> – If <cite>weights_initializer</cite> is not a valid string</li>
<li><code class="xref py py-exc docutils literal"><span class="pre">ValueError</span></code> – If <cite>biases_initializer</cite> is not a valid string</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="FFnetwork.layer.Layer.assign_layer_params">
<code class="descname">assign_layer_params</code><span class="sig-paren">(</span><em>sess</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/FFnetwork/layer.html#Layer.assign_layer_params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#FFnetwork.layer.Layer.assign_layer_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Read weights/biases in numpy arrays into tf Variables</p>
</dd></dl>

<dl class="method">
<dt id="FFnetwork.layer.Layer.assign_reg_vals">
<code class="descname">assign_reg_vals</code><span class="sig-paren">(</span><em>sess</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/FFnetwork/layer.html#Layer.assign_reg_vals"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#FFnetwork.layer.Layer.assign_reg_vals" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrapper function for assigning regularization values</p>
</dd></dl>

<dl class="method">
<dt id="FFnetwork.layer.Layer.build_graph">
<code class="descname">build_graph</code><span class="sig-paren">(</span><em>inputs</em>, <em>params_dict=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/FFnetwork/layer.html#Layer.build_graph"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#FFnetwork.layer.Layer.build_graph" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="FFnetwork.layer.Layer.define_regularization_loss">
<code class="descname">define_regularization_loss</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/FFnetwork/layer.html#Layer.define_regularization_loss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#FFnetwork.layer.Layer.define_regularization_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrapper function for building regularization portion of graph</p>
</dd></dl>

<dl class="method">
<dt id="FFnetwork.layer.Layer.get_reg_pen">
<code class="descname">get_reg_pen</code><span class="sig-paren">(</span><em>sess</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/FFnetwork/layer.html#Layer.get_reg_pen"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#FFnetwork.layer.Layer.get_reg_pen" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrapper function for returning regularization penalty struct</p>
</dd></dl>

<dl class="method">
<dt id="FFnetwork.layer.Layer.set_regularization">
<code class="descname">set_regularization</code><span class="sig-paren">(</span><em>reg_type</em>, <em>reg_val</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/FFnetwork/layer.html#Layer.set_regularization"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#FFnetwork.layer.Layer.set_regularization" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrapper function for setting regularization</p>
</dd></dl>

<dl class="method">
<dt id="FFnetwork.layer.Layer.write_layer_params">
<code class="descname">write_layer_params</code><span class="sig-paren">(</span><em>sess</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/FFnetwork/layer.html#Layer.write_layer_params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#FFnetwork.layer.Layer.write_layer_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Write weights/biases in tf Variables to numpy arrays</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="FFnetwork.layer.convLayer">
<em class="property">class </em><code class="descclassname">FFnetwork.layer.</code><code class="descname">convLayer</code><span class="sig-paren">(</span><em>scope=None</em>, <em>input_dims=None</em>, <em>num_filters=None</em>, <em>filter_dims=None</em>, <em>shift_spacing=1</em>, <em>activation_func='relu'</em>, <em>normalize_weights=False</em>, <em>weights_initializer='trunc_normal'</em>, <em>biases_initializer='zeros'</em>, <em>reg_initializer=None</em>, <em>num_inh=0</em>, <em>pos_constraint=False</em>, <em>log_activations=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/FFnetwork/layer.html#convLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#FFnetwork.layer.convLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#FFnetwork.layer.Layer" title="FFnetwork.layer.Layer"><code class="xref py py-class docutils literal"><span class="pre">FFnetwork.layer.Layer</span></code></a></p>
<p>Implementation of fully connected neural network layer</p>
<dl class="attribute">
<dt id="FFnetwork.layer.convLayer.scope">
<code class="descname">scope</code><a class="headerlink" href="#FFnetwork.layer.convLayer.scope" title="Permalink to this definition">¶</a></dt>
<dd><p><em>str</em> – name scope for variables and operations in layer</p>
</dd></dl>

<dl class="attribute">
<dt id="FFnetwork.layer.convLayer.num_inputs">
<code class="descname">num_inputs</code><a class="headerlink" href="#FFnetwork.layer.convLayer.num_inputs" title="Permalink to this definition">¶</a></dt>
<dd><p><em>int</em> – number of inputs to layer</p>
</dd></dl>

<dl class="attribute">
<dt id="FFnetwork.layer.convLayer.num_outputs">
<code class="descname">num_outputs</code><a class="headerlink" href="#FFnetwork.layer.convLayer.num_outputs" title="Permalink to this definition">¶</a></dt>
<dd><p><em>int</em> – number of outputs of layer</p>
</dd></dl>

<dl class="attribute">
<dt id="FFnetwork.layer.convLayer.outputs">
<code class="descname">outputs</code><a class="headerlink" href="#FFnetwork.layer.convLayer.outputs" title="Permalink to this definition">¶</a></dt>
<dd><p><em>tf Tensor</em> – output of layer</p>
</dd></dl>

<dl class="attribute">
<dt id="FFnetwork.layer.convLayer.num_inh">
<code class="descname">num_inh</code><a class="headerlink" href="#FFnetwork.layer.convLayer.num_inh" title="Permalink to this definition">¶</a></dt>
<dd><p><em>int</em> – number of inhibitory units in layer</p>
</dd></dl>

<dl class="attribute">
<dt id="FFnetwork.layer.convLayer.weights_ph">
<code class="descname">weights_ph</code><a class="headerlink" href="#FFnetwork.layer.convLayer.weights_ph" title="Permalink to this definition">¶</a></dt>
<dd><p><em>tf placeholder</em> – placeholder for weights in layer</p>
</dd></dl>

<dl class="attribute">
<dt id="FFnetwork.layer.convLayer.biases_ph">
<code class="descname">biases_ph</code><a class="headerlink" href="#FFnetwork.layer.convLayer.biases_ph" title="Permalink to this definition">¶</a></dt>
<dd><p><em>tf placeholder</em> – placeholder for biases in layer</p>
</dd></dl>

<dl class="attribute">
<dt id="FFnetwork.layer.convLayer.weights_var">
<code class="descname">weights_var</code><a class="headerlink" href="#FFnetwork.layer.convLayer.weights_var" title="Permalink to this definition">¶</a></dt>
<dd><p><em>tf Tensor</em> – weights in layer</p>
</dd></dl>

<dl class="attribute">
<dt id="FFnetwork.layer.convLayer.biases_var">
<code class="descname">biases_var</code><a class="headerlink" href="#FFnetwork.layer.convLayer.biases_var" title="Permalink to this definition">¶</a></dt>
<dd><p><em>tf Tensor</em> – biases in layer</p>
</dd></dl>

<dl class="attribute">
<dt id="FFnetwork.layer.convLayer.weights">
<code class="descname">weights</code><a class="headerlink" href="#FFnetwork.layer.convLayer.weights" title="Permalink to this definition">¶</a></dt>
<dd><p><em>numpy array</em> – shadow variable of <cite>weights_var</cite> that allows for
easier manipulation outside of tf sessions</p>
</dd></dl>

<dl class="attribute">
<dt id="FFnetwork.layer.convLayer.biases">
<code class="descname">biases</code><a class="headerlink" href="#FFnetwork.layer.convLayer.biases" title="Permalink to this definition">¶</a></dt>
<dd><p><em>numpy array</em> – shadow variable of <cite>biases_var</cite> that allows for
easier manipulation outside of tf sessions</p>
</dd></dl>

<dl class="attribute">
<dt id="FFnetwork.layer.convLayer.activation_func">
<code class="descname">activation_func</code><a class="headerlink" href="#FFnetwork.layer.convLayer.activation_func" title="Permalink to this definition">¶</a></dt>
<dd><p><em>tf activation function</em> – activation function in layer</p>
</dd></dl>

<dl class="attribute">
<dt id="FFnetwork.layer.convLayer.reg">
<code class="descname">reg</code><a class="headerlink" href="#FFnetwork.layer.convLayer.reg" title="Permalink to this definition">¶</a></dt>
<dd><p><em>Regularization object</em> – holds regularizations values and matrices
(as tf constants) for layer</p>
</dd></dl>

<dl class="attribute">
<dt id="FFnetwork.layer.convLayer.ei_mask_var">
<code class="descname">ei_mask_var</code><a class="headerlink" href="#FFnetwork.layer.convLayer.ei_mask_var" title="Permalink to this definition">¶</a></dt>
<dd><p><em>tf constant</em> – mask of +/-1s to multiply output of layer</p>
</dd></dl>

<dl class="attribute">
<dt id="FFnetwork.layer.convLayer.ei_mask">
<code class="descname">ei_mask</code><a class="headerlink" href="#FFnetwork.layer.convLayer.ei_mask" title="Permalink to this definition">¶</a></dt>
<dd><p><em>list</em> – mask of +/-1s to multiply output of layer; shadows
<cite>ei_mask_tf</cite> for easier manipulation outside of tf sessions</p>
</dd></dl>

<dl class="attribute">
<dt id="FFnetwork.layer.convLayer.pos_constraint">
<code class="descname">pos_constraint</code><a class="headerlink" href="#FFnetwork.layer.convLayer.pos_constraint" title="Permalink to this definition">¶</a></dt>
<dd><p><em>bool</em> – positivity constraint on weights in layer</p>
</dd></dl>

<dl class="attribute">
<dt id="FFnetwork.layer.convLayer.log">
<code class="descname">log</code><a class="headerlink" href="#FFnetwork.layer.convLayer.log" title="Permalink to this definition">¶</a></dt>
<dd><p><em>bool</em> – use tf summary writers on layer output</p>
</dd></dl>

<dl class="method">
<dt id="FFnetwork.layer.convLayer.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>scope=None</em>, <em>input_dims=None</em>, <em>num_filters=None</em>, <em>filter_dims=None</em>, <em>shift_spacing=1</em>, <em>activation_func='relu'</em>, <em>normalize_weights=False</em>, <em>weights_initializer='trunc_normal'</em>, <em>biases_initializer='zeros'</em>, <em>reg_initializer=None</em>, <em>num_inh=0</em>, <em>pos_constraint=False</em>, <em>log_activations=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/FFnetwork/layer.html#convLayer.__init__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#FFnetwork.layer.convLayer.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Constructor for convLayer class</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>scope</strong> (<em>str</em>) – name scope for variables and operations in layer</li>
<li><strong>input_dims</strong> (<em>int</em>) – dimension of input data</li>
<li><strong>num_outputs</strong> (<em>int</em>) – dimension of output data</li>
<li><strong>activation_func</strong> (<em>str</em><em>, </em><em>optional</em>) – pointwise function applied to
output of affine transformation
[‘relu’] | ‘sigmoid’ | ‘tanh’ | ‘identity’ | ‘softplus’ | ‘elu’ | ‘quad’</li>
<li><strong>weights_initializer</strong> (<em>str</em><em>, </em><em>optional</em>) – initializer for the weights
[‘trunc_normal’] | ‘normal’ | ‘zeros’</li>
<li><strong>biases_initializer</strong> (<em>str</em><em>, </em><em>optional</em>) – initializer for the biases
‘trunc_normal’ | ‘normal’ | [‘zeros’]</li>
<li><strong>reg_initializer</strong> (<em>dict</em><em>, </em><em>optional</em>) – see Regularizer docs for info</li>
<li><strong>num_inh</strong> (<em>int</em><em>, </em><em>optional</em>) – number of inhibitory units in layer</li>
<li><strong>pos_constraint</strong> (<em>bool</em><em>, </em><em>optional</em>) – True to constrain layer weights to be
positive</li>
<li><strong>log_activations</strong> (<em>bool</em><em>, </em><em>optional</em>) – True to use tf.summary on layer
activations</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Raises:</th><td class="field-body"><ul class="first last simple">
<li><code class="xref py py-exc docutils literal"><span class="pre">TypeError</span></code> – If <cite>variable_scope</cite> is not specified</li>
<li><code class="xref py py-exc docutils literal"><span class="pre">TypeError</span></code> – If <cite>inputs</cite> is not specified</li>
<li><code class="xref py py-exc docutils literal"><span class="pre">TypeError</span></code> – If <cite>num_inputs</cite> or <cite>num_outputs</cite> is not specified</li>
<li><code class="xref py py-exc docutils literal"><span class="pre">ValueError</span></code> – If <cite>num_inh</cite> is greater than total number of units</li>
<li><code class="xref py py-exc docutils literal"><span class="pre">ValueError</span></code> – If <cite>activation_func</cite> is not a valid string</li>
<li><code class="xref py py-exc docutils literal"><span class="pre">ValueError</span></code> – If <cite>weights_initializer</cite> is not a valid string</li>
<li><code class="xref py py-exc docutils literal"><span class="pre">ValueError</span></code> – If <cite>biases_initializer</cite> is not a valid string</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="FFnetwork.layer.convLayer.build_graph">
<code class="descname">build_graph</code><span class="sig-paren">(</span><em>inputs</em>, <em>params_dict=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/FFnetwork/layer.html#convLayer.build_graph"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#FFnetwork.layer.convLayer.build_graph" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="FFnetwork.layer.sepLayer">
<em class="property">class </em><code class="descclassname">FFnetwork.layer.</code><code class="descname">sepLayer</code><span class="sig-paren">(</span><em>scope=None</em>, <em>input_dims=None</em>, <em>output_dims=None</em>, <em>activation_func='relu'</em>, <em>normalize_weights=False</em>, <em>weights_initializer='trunc_normal'</em>, <em>biases_initializer='zeros'</em>, <em>reg_initializer=None</em>, <em>num_inh=0</em>, <em>pos_constraint=False</em>, <em>log_activations=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/FFnetwork/layer.html#sepLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#FFnetwork.layer.sepLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#FFnetwork.layer.Layer" title="FFnetwork.layer.Layer"><code class="xref py py-class docutils literal"><span class="pre">FFnetwork.layer.Layer</span></code></a></p>
<p>Implementation of fully connected neural network layer</p>
<dl class="attribute">
<dt id="FFnetwork.layer.sepLayer.scope">
<code class="descname">scope</code><a class="headerlink" href="#FFnetwork.layer.sepLayer.scope" title="Permalink to this definition">¶</a></dt>
<dd><p><em>str</em> – name scope for variables and operations in layer</p>
</dd></dl>

<dl class="attribute">
<dt id="FFnetwork.layer.sepLayer.input_dims">
<code class="descname">input_dims</code><a class="headerlink" href="#FFnetwork.layer.sepLayer.input_dims" title="Permalink to this definition">¶</a></dt>
<dd><p><em>int</em> – 3-d list of numbers for input dimensions</p>
</dd></dl>

<dl class="attribute">
<dt id="FFnetwork.layer.sepLayer.output_dims">
<code class="descname">output_dims</code><a class="headerlink" href="#FFnetwork.layer.sepLayer.output_dims" title="Permalink to this definition">¶</a></dt>
<dd><p><em>int</em> – 3-d list of numbers for input dimensions</p>
</dd></dl>

<dl class="attribute">
<dt id="FFnetwork.layer.sepLayer.outputs">
<code class="descname">outputs</code><a class="headerlink" href="#FFnetwork.layer.sepLayer.outputs" title="Permalink to this definition">¶</a></dt>
<dd><p><em>tf Tensor</em> – output of layer</p>
</dd></dl>

<dl class="attribute">
<dt id="FFnetwork.layer.sepLayer.num_inh">
<code class="descname">num_inh</code><a class="headerlink" href="#FFnetwork.layer.sepLayer.num_inh" title="Permalink to this definition">¶</a></dt>
<dd><p><em>int</em> – number of inhibitory units in layer</p>
</dd></dl>

<dl class="attribute">
<dt id="FFnetwork.layer.sepLayer.weights_ph">
<code class="descname">weights_ph</code><a class="headerlink" href="#FFnetwork.layer.sepLayer.weights_ph" title="Permalink to this definition">¶</a></dt>
<dd><p><em>tf placeholder</em> – placeholder for weights in layer</p>
</dd></dl>

<dl class="attribute">
<dt id="FFnetwork.layer.sepLayer.biases_ph">
<code class="descname">biases_ph</code><a class="headerlink" href="#FFnetwork.layer.sepLayer.biases_ph" title="Permalink to this definition">¶</a></dt>
<dd><p><em>tf placeholder</em> – placeholder for biases in layer</p>
</dd></dl>

<dl class="attribute">
<dt id="FFnetwork.layer.sepLayer.weights_var">
<code class="descname">weights_var</code><a class="headerlink" href="#FFnetwork.layer.sepLayer.weights_var" title="Permalink to this definition">¶</a></dt>
<dd><p><em>tf Tensor</em> – weights in layer</p>
</dd></dl>

<dl class="attribute">
<dt id="FFnetwork.layer.sepLayer.biases_var">
<code class="descname">biases_var</code><a class="headerlink" href="#FFnetwork.layer.sepLayer.biases_var" title="Permalink to this definition">¶</a></dt>
<dd><p><em>tf Tensor</em> – biases in layer</p>
</dd></dl>

<dl class="attribute">
<dt id="FFnetwork.layer.sepLayer.weights">
<code class="descname">weights</code><a class="headerlink" href="#FFnetwork.layer.sepLayer.weights" title="Permalink to this definition">¶</a></dt>
<dd><p><em>numpy array</em> – shadow variable of <cite>weights_var</cite> that allows for
easier manipulation outside of tf sessions</p>
</dd></dl>

<dl class="attribute">
<dt id="FFnetwork.layer.sepLayer.biases">
<code class="descname">biases</code><a class="headerlink" href="#FFnetwork.layer.sepLayer.biases" title="Permalink to this definition">¶</a></dt>
<dd><p><em>numpy array</em> – shadow variable of <cite>biases_var</cite> that allows for
easier manipulation outside of tf sessions</p>
</dd></dl>

<dl class="attribute">
<dt id="FFnetwork.layer.sepLayer.activation_func">
<code class="descname">activation_func</code><a class="headerlink" href="#FFnetwork.layer.sepLayer.activation_func" title="Permalink to this definition">¶</a></dt>
<dd><p><em>tf activation function</em> – activation function in layer</p>
</dd></dl>

<dl class="attribute">
<dt id="FFnetwork.layer.sepLayer.reg">
<code class="descname">reg</code><a class="headerlink" href="#FFnetwork.layer.sepLayer.reg" title="Permalink to this definition">¶</a></dt>
<dd><p><em>Regularization object</em> – holds regularizations values and matrices
(as tf constants) for layer</p>
</dd></dl>

<dl class="attribute">
<dt id="FFnetwork.layer.sepLayer.ei_mask_var">
<code class="descname">ei_mask_var</code><a class="headerlink" href="#FFnetwork.layer.sepLayer.ei_mask_var" title="Permalink to this definition">¶</a></dt>
<dd><p><em>tf constant</em> – mask of +/-1s to multiply output of layer</p>
</dd></dl>

<dl class="attribute">
<dt id="FFnetwork.layer.sepLayer.ei_mask">
<code class="descname">ei_mask</code><a class="headerlink" href="#FFnetwork.layer.sepLayer.ei_mask" title="Permalink to this definition">¶</a></dt>
<dd><p><em>list</em> – mask of +/-1s to multiply output of layer; shadows
<cite>ei_mask_tf</cite> for easier manipulation outside of tf sessions</p>
</dd></dl>

<dl class="attribute">
<dt id="FFnetwork.layer.sepLayer.pos_constraint">
<code class="descname">pos_constraint</code><a class="headerlink" href="#FFnetwork.layer.sepLayer.pos_constraint" title="Permalink to this definition">¶</a></dt>
<dd><p><em>bool</em> – positivity constraint on weights in layer</p>
</dd></dl>

<dl class="attribute">
<dt id="FFnetwork.layer.sepLayer.log">
<code class="descname">log</code><a class="headerlink" href="#FFnetwork.layer.sepLayer.log" title="Permalink to this definition">¶</a></dt>
<dd><p><em>bool</em> – use tf summary writers on layer output</p>
</dd></dl>

<dl class="method">
<dt id="FFnetwork.layer.sepLayer.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>scope=None</em>, <em>input_dims=None</em>, <em>output_dims=None</em>, <em>activation_func='relu'</em>, <em>normalize_weights=False</em>, <em>weights_initializer='trunc_normal'</em>, <em>biases_initializer='zeros'</em>, <em>reg_initializer=None</em>, <em>num_inh=0</em>, <em>pos_constraint=False</em>, <em>log_activations=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/FFnetwork/layer.html#sepLayer.__init__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#FFnetwork.layer.sepLayer.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Constructor for convLayer class</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>scope</strong> (<em>str</em>) – name scope for variables and operations in layer</li>
<li><strong>input_dims</strong> (<em>int</em>) – dimensions of input data</li>
<li><strong>output_dims</strong> (<em>int</em>) – dimensions of output data</li>
<li><strong>activation_func</strong> (<em>str</em><em>, </em><em>optional</em>) – pointwise function applied to
output of affine transformation
[‘relu’] | ‘sigmoid’ | ‘tanh’ | ‘identity’ | ‘softplus’ | ‘elu’ | ‘quad’</li>
<li><strong>weights_initializer</strong> (<em>str</em><em>, </em><em>optional</em>) – initializer for the weights
[‘trunc_normal’] | ‘normal’ | ‘zeros’</li>
<li><strong>biases_initializer</strong> (<em>str</em><em>, </em><em>optional</em>) – initializer for the biases
‘trunc_normal’ | ‘normal’ | [‘zeros’]</li>
<li><strong>reg_initializer</strong> (<em>dict</em><em>, </em><em>optional</em>) – see Regularizer docs for info</li>
<li><strong>num_inh</strong> (<em>int</em><em>, </em><em>optional</em>) – number of inhibitory units in layer</li>
<li><strong>pos_constraint</strong> (<em>bool</em><em>, </em><em>optional</em>) – True to constrain layer weights to be
positive</li>
<li><strong>log_activations</strong> (<em>bool</em><em>, </em><em>optional</em>) – True to use tf.summary on layer
activations</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Raises:</th><td class="field-body"><ul class="first last simple">
<li><code class="xref py py-exc docutils literal"><span class="pre">TypeError</span></code> – If <cite>variable_scope</cite> is not specified</li>
<li><code class="xref py py-exc docutils literal"><span class="pre">TypeError</span></code> – If <cite>inputs</cite> is not specified</li>
<li><code class="xref py py-exc docutils literal"><span class="pre">TypeError</span></code> – If <cite>num_inputs</cite> or <cite>num_outputs</cite> is not specified</li>
<li><code class="xref py py-exc docutils literal"><span class="pre">ValueError</span></code> – If <cite>num_inh</cite> is greater than total number of units</li>
<li><code class="xref py py-exc docutils literal"><span class="pre">ValueError</span></code> – If <cite>activation_func</cite> is not a valid string</li>
<li><code class="xref py py-exc docutils literal"><span class="pre">ValueError</span></code> – If <cite>weights_initializer</cite> is not a valid string</li>
<li><code class="xref py py-exc docutils literal"><span class="pre">ValueError</span></code> – If <cite>biases_initializer</cite> is not a valid string</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="FFnetwork.layer.sepLayer.build_graph">
<code class="descname">build_graph</code><span class="sig-paren">(</span><em>inputs</em>, <em>params_dict=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/FFnetwork/layer.html#sepLayer.build_graph"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#FFnetwork.layer.sepLayer.build_graph" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-FFnetwork.regularization">
<span id="ffnetwork-regularization-module"></span><h2>FFnetwork.regularization module<a class="headerlink" href="#module-FFnetwork.regularization" title="Permalink to this headline">¶</a></h2>
<p>Basic network-building tools</p>
<dl class="class">
<dt id="FFnetwork.regularization.Regularization">
<em class="property">class </em><code class="descclassname">FFnetwork.regularization.</code><code class="descname">Regularization</code><span class="sig-paren">(</span><em>input_dims=None</em>, <em>num_outputs=None</em>, <em>vals=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/FFnetwork/regularization.html#Regularization"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#FFnetwork.regularization.Regularization" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">object</span></code></p>
<p>Class for handling layer-wise regularization</p>
<dl class="attribute">
<dt id="FFnetwork.regularization.Regularization.vals">
<code class="descname">vals</code><a class="headerlink" href="#FFnetwork.regularization.Regularization.vals" title="Permalink to this definition">¶</a></dt>
<dd><p><em>dict</em> – values for different types of regularization stored as
floats</p>
</dd></dl>

<dl class="attribute">
<dt id="FFnetwork.regularization.Regularization.vals_ph">
<code class="descname">vals_ph</code><a class="headerlink" href="#FFnetwork.regularization.Regularization.vals_ph" title="Permalink to this definition">¶</a></dt>
<dd><p><em>dict</em> – placeholders for different types of regularization to
simplify the tf Graph when experimenting with different reg vals</p>
</dd></dl>

<dl class="attribute">
<dt id="FFnetwork.regularization.Regularization.vals_var">
<code class="descname">vals_var</code><a class="headerlink" href="#FFnetwork.regularization.Regularization.vals_var" title="Permalink to this definition">¶</a></dt>
<dd><p><em>dict</em> – values for different types of regularization stored as
(un-trainable) tf.Variables</p>
</dd></dl>

<dl class="attribute">
<dt id="FFnetwork.regularization.Regularization.mats">
<code class="descname">mats</code><a class="headerlink" href="#FFnetwork.regularization.Regularization.mats" title="Permalink to this definition">¶</a></dt>
<dd><p><em>dict</em> – matrices for different types of regularization stored as
tf constants</p>
</dd></dl>

<dl class="attribute">
<dt id="FFnetwork.regularization.Regularization.penalties">
<code class="descname">penalties</code><a class="headerlink" href="#FFnetwork.regularization.Regularization.penalties" title="Permalink to this definition">¶</a></dt>
<dd><p><em>dict</em> – tf ops for evaluating different regularization
penalties</p>
</dd></dl>

<dl class="attribute">
<dt id="FFnetwork.regularization.Regularization.input_dims">
<code class="descname">input_dims</code><a class="headerlink" href="#FFnetwork.regularization.Regularization.input_dims" title="Permalink to this definition">¶</a></dt>
<dd><p><em>list</em> – dimensions of layer input size; for constructing reg
matrices</p>
</dd></dl>

<dl class="attribute">
<dt id="FFnetwork.regularization.Regularization.num_outputs">
<code class="descname">num_outputs</code><a class="headerlink" href="#FFnetwork.regularization.Regularization.num_outputs" title="Permalink to this definition">¶</a></dt>
<dd><p><em>int</em> – dimension of layer output size; for generating
target weights in norm2</p>
</dd></dl>

<dl class="method">
<dt id="FFnetwork.regularization.Regularization.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>input_dims=None</em>, <em>num_outputs=None</em>, <em>vals=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/FFnetwork/regularization.html#Regularization.__init__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#FFnetwork.regularization.Regularization.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Constructor for Regularization class</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>input_dims</strong> (<em>int</em>) – dimension of input size (for building reg mats)</li>
<li><strong>num_outputs</strong> (<em>int</em>) – number of outputs (for normalization in norm2)</li>
<li><strong>vals</strong> (<em>dict</em><em>, </em><em>optional</em>) – key-value pairs specifying value for each
type of regularization</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Raises:</th><td class="field-body"><ul class="first last simple">
<li><code class="xref py py-exc docutils literal"><span class="pre">TypeError</span></code> – If <cite>input_dims</cite> is not specified</li>
<li><code class="xref py py-exc docutils literal"><span class="pre">TypeError</span></code> – If <cite>num_outputs</cite> is not specified</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="FFnetwork.regularization.Regularization.assign_reg_vals">
<code class="descname">assign_reg_vals</code><span class="sig-paren">(</span><em>sess</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/FFnetwork/regularization.html#Regularization.assign_reg_vals"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#FFnetwork.regularization.Regularization.assign_reg_vals" title="Permalink to this definition">¶</a></dt>
<dd><p>Update regularization values in default tf Graph</p>
</dd></dl>

<dl class="method">
<dt id="FFnetwork.regularization.Regularization.define_reg_loss">
<code class="descname">define_reg_loss</code><span class="sig-paren">(</span><em>weights</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/FFnetwork/regularization.html#Regularization.define_reg_loss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#FFnetwork.regularization.Regularization.define_reg_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Define regularization loss in default tf Graph</p>
</dd></dl>

<dl class="method">
<dt id="FFnetwork.regularization.Regularization.get_reg_penalty">
<code class="descname">get_reg_penalty</code><span class="sig-paren">(</span><em>sess</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/FFnetwork/regularization.html#Regularization.get_reg_penalty"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#FFnetwork.regularization.Regularization.get_reg_penalty" title="Permalink to this definition">¶</a></dt>
<dd><p>Build dictionary that contains regularization penalty from each
regularization type</p>
</dd></dl>

<dl class="method">
<dt id="FFnetwork.regularization.Regularization.reg_copy">
<code class="descname">reg_copy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/FFnetwork/regularization.html#Regularization.reg_copy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#FFnetwork.regularization.Regularization.reg_copy" title="Permalink to this definition">¶</a></dt>
<dd><p>Copy regularization to new structure</p>
</dd></dl>

<dl class="method">
<dt id="FFnetwork.regularization.Regularization.set_reg_val">
<code class="descname">set_reg_val</code><span class="sig-paren">(</span><em>reg_type</em>, <em>reg_val</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/FFnetwork/regularization.html#Regularization.set_reg_val"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#FFnetwork.regularization.Regularization.set_reg_val" title="Permalink to this definition">¶</a></dt>
<dd><p>Set regularization value in self.vals dict (doesn’t affect a tf
Graph until a session is run and <cite>assign_reg_vals</cite> is called)</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>reg_type</strong> (<em>str</em>) – see <cite>_allowed_reg_types</cite> for options</li>
<li><strong>reg_val</strong> (<em>float</em>) – value of regularization parameter</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">True if <cite>reg_type</cite> has not been previously set</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first">bool</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Raises:</th><td class="field-body"><ul class="first last simple">
<li><code class="xref py py-exc docutils literal"><span class="pre">ValueError</span></code> – If <cite>reg_type</cite> is not a valid regularization type</li>
<li><code class="xref py py-exc docutils literal"><span class="pre">ValueError</span></code> – If <cite>reg_val</cite> is less than 0.0</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="FFnetwork.regularization.Sep_Regularization">
<em class="property">class </em><code class="descclassname">FFnetwork.regularization.</code><code class="descname">Sep_Regularization</code><span class="sig-paren">(</span><em>input_dims=None</em>, <em>num_outputs=None</em>, <em>vals=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/FFnetwork/regularization.html#Sep_Regularization"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#FFnetwork.regularization.Sep_Regularization" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#FFnetwork.regularization.Regularization" title="FFnetwork.regularization.Regularization"><code class="xref py py-class docutils literal"><span class="pre">FFnetwork.regularization.Regularization</span></code></a></p>
<p>Child class that adjusts regularization for separable layers</p>
<dl class="method">
<dt id="FFnetwork.regularization.Sep_Regularization.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>input_dims=None</em>, <em>num_outputs=None</em>, <em>vals=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/FFnetwork/regularization.html#Sep_Regularization.__init__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#FFnetwork.regularization.Sep_Regularization.__init__" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="ffnetwork-side-network-module">
<h2>FFnetwork.side_network module<a class="headerlink" href="#ffnetwork-side-network-module" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="module-FFnetwork">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-FFnetwork" title="Permalink to this headline">¶</a></h2>
</div>
</div>


           </div>
           <div class="articleComments">
            
           </div>
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, Dan Butts, Matt Whiteway.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'2.0',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>